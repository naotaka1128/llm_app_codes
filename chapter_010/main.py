# GitHub: https://github.com/naotaka1128/llm_app_codes/chapter_010/main.py

import streamlit as st
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.agents import create_tool_calling_agent, AgentExecutor

from langchain.agents import AgentExecutor
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain.memory import ConversationBufferWindowMemory

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from tools.fetch_qa_content import fetch_qa_content
from tools.fetch_stores_by_prefecture import fetch_stores_by_prefecture


from dotenv import load_dotenv
load_dotenv()

CUSTOM_SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ—¥æœ¬ã®æ ¼å®‰æºå¸¯é›»è©±ä¼šç¤¾ã€Œãƒ™ã‚¢ãƒ¼ãƒ¢ãƒã‚¤ãƒ«ã€ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ(CS)æ‹…å½“è€…ã§ã™ã€‚
ãŠå®¢æ§˜ã‹ã‚‰ã®ãŠå•ã„åˆã‚ã›ã«å¯¾ã—ã¦ã€èª å®Ÿã‹ã¤æ­£ç¢ºãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚

æºå¸¯é›»è©±ä¼šç¤¾ã®CSã¨ã—ã¦ã€å½“ç¤¾ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚„æºå¸¯é›»è©±ã«é–¢ã™ã‚‹ä¸€èˆ¬çš„ãªçŸ¥è­˜ã«ã¤ã„ã¦ã®ã¿ç­”ãˆã¾ã™ã€‚
ãã‚Œä»¥å¤–ã®ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹è³ªå•ã«ã¯ã€ä¸é‡ã«ãŠæ–­ã‚Šã—ã¦ãã ã•ã„ã€‚

å›ç­”ã®æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã€Œãƒ™ã‚¢ãƒ¼ãƒ¢ãƒã‚¤ãƒ«ã€ã«é–¢ã™ã‚‹è³ªå•ã‚’å—ã‘ãŸéš›ã¯ã€
å¿…ãšãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚

ãŠå®¢æ§˜ãŒè³ªå•ã«ä½¿ç”¨ã—ãŸè¨€èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ä¾‹ãˆã°ã€ãŠå®¢æ§˜ãŒè‹±èªã§è³ªå•ã•ã‚ŒãŸå ´åˆã¯ã€å¿…ãšè‹±èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚¹ãƒšã‚¤ãƒ³èªãªã‚‰ã‚¹ãƒšã‚¤ãƒ³èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã™ã‚‹éš›ã€ä¸æ˜ãªç‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ãŠå®¢æ§˜ã«ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚
ãã‚Œã«ã‚ˆã‚Šã€ãŠå®¢æ§˜ã®æ„å›³ã‚’æŠŠæ¡ã—ã¦ã€é©åˆ‡ãªå›ç­”ã‚’è¡Œãˆã¾ã™ã€‚

ä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œåº—èˆ—ã¯ã©ã“ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€ã¨è³ªå•ã—ãŸå ´åˆã€
ã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å±…ä½éƒ½é“åºœçœŒã‚’å°‹ã­ã¦ãã ã•ã„ã€‚

æ—¥æœ¬å…¨å›½ã®åº—èˆ—ã®å ´æ‰€ã‚’çŸ¥ã‚ŠãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã»ã¨ã‚“ã©ã„ã¾ã›ã‚“ã€‚
è‡ªåˆ†ã®éƒ½é“åºœçœŒå†…ã®åº—èˆ—ã®å ´æ‰€ã‚’çŸ¥ã‚ŠãŸã„ã®ã§ã™ã€‚
ã—ãŸãŒã£ã¦ã€æ—¥æœ¬å…¨å›½ã®åº—èˆ—ã‚’æ¤œç´¢ã—ã¦å›ç­”ã™ã‚‹ã®ã§ã¯ãªãã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æœ¬å½“ã«ç†è§£ã™ã‚‹ã¾ã§å›ç­”ã—ãªã„ã§ãã ã•ã„ï¼

ã‚ãã¾ã§ã“ã‚Œã¯ä¸€ä¾‹ã§ã™ã€‚
ãã®ä»–ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãŠå®¢æ§˜ã®æ„å›³ã‚’ç†è§£ã—ã€é©åˆ‡ãªå›ç­”ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
"""


def init_page():
    st.set_page_config(
        page_title="ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ",
        page_icon="ğŸ»"
    )
    st.header("ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆğŸ»")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        welcome_message = "ãƒ™ã‚¢ãƒ¼ãƒ¢ãƒã‚¤ãƒ« ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã¸ã‚ˆã†ã“ãã€‚ã”è³ªå•ã‚’ã©ã†ãğŸ»"
        st.session_state.messages = [
            {"role": "assistant", "content": welcome_message}
        ]
        st.session_state['memory'] = ConversationBufferWindowMemory(
            return_messages=True,
            memory_key="chat_history",
            k=10
        )


def select_model():
    models = ("GPT-4", "Claude 3 Sonnet", "Gemini 1.5 Pro", "GPT-3.5 (not recommended)")
    model = st.sidebar.radio("Choose a model:", models)
    if model == "GPT-3.5 (not recommended)":
        return ChatOpenAI(
            temperature=0, model_name="gpt-3.5-turbo")
    elif model == "GPT-4":
        return ChatOpenAI(
            temperature=0, model_name="gpt-4-turbo")
    elif model == "Claude 3 Sonnet":
        return ChatAnthropic(
            temperature=0, model_name="claude-3-sonnet-20240229")
    elif model == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(
            temperature=0, model="gemini-1.5-pro-latest")


def create_agent():
    ## https://learn.deeplearning.ai/functions-tools-agents-langchain/lesson/7/conversational-agent
    tools = [fetch_qa_content, fetch_stores_by_prefecture]
    prompt = ChatPromptTemplate.from_messages([
        ("system", CUSTOM_SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = select_model()
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=st.session_state['memory']
    )


def main():
    init_page()
    init_messages()
    customer_support_agent = create_agent()

    for msg in st.session_state['memory'].chat_memory.messages:
        st.chat_message(msg.type).write(msg.content)

    if prompt := st.chat_input(placeholder="æ³•äººã§å¥‘ç´„ã™ã‚‹ã“ã¨ã¯ã§ãã‚‹ã®ï¼Ÿ"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(
                st.container(), expand_new_thoughts=True)
            response = customer_support_agent.invoke(
                {'input': prompt},
                config=RunnableConfig({'callbacks': [st_cb]})
            )
            st.write(response["output"])


if __name__ == '__main__':
    main()
